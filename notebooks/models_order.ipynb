{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MOVE FILE: c:\\Users\\rashe\\Dropbox\\1_Work\\1a_gitrepoz\\time_series\\notebooks\\3.io_Models_Order.ipynb\n",
                "{\n",
                "    \"cells\": [\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-8f998a84\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"x_train = df[WQP].dropna()\",\n",
                "                \"print(WQP)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-2aaf74b5\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"df_results = pd.DataFrame()\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-1b1908f4\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"# convert an array of values into a dataset matrix\",\n",
                "                \"def create_dataset(values, look_back):\",\n",
                "                \"    np.random.seed(42)\",\n",
                "                \"     # set empty lists \",\n",
                "                \"    _x, _y = [], []\",\n",
                "                \"    for i in range(len(values)-look_back-1):\",\n",
                "                \"        a = values[i:(i+look_back)]      # stack a list of values\",\n",
                "                \"        _x.append(a)                        # set x\",\n",
                "                \"        _y.append(values[i + look_back]) # set y\",\n",
                "                \"    return np.array(_x), np.array(_y)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-b043e1f7\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"num = 2\",\n",
                "                \"values = df[WQP].values\",\n",
                "                \"# normalize the dataset\",\n",
                "                \"scaler = MinMaxScaler(feature_range=(0, 1))\",\n",
                "                \"dataset = scaler.fit_transform(values[~np.isnan(values)].reshape(-1, 1))\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-05e45a7e\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"# split into train and test sets\",\n",
                "                \"train_size = int(len(dataset) * split)\",\n",
                "                \"test_size = len(dataset) - train_size\",\n",
                "                \"train, test = dataset[:train_size], dataset[train_size:]\",\n",
                "                \"# reshape into X=t and Y=t+1\",\n",
                "                \"#look_back = 20\",\n",
                "                \"train_x, train_y = create_dataset(train, look_back)\",\n",
                "                \"test_x, test_y = create_dataset(test, look_back)\",\n",
                "                \"# reshape input to be [samples, time steps, features]\",\n",
                "                \"train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\",\n",
                "                \"test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-ed3b6ccd\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"Lgr = test_size-wz-1\",\n",
                "                \"dLgr = train_size+wz+1\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-1f8dfed5\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"   def scatter_plot(y_true, y_pred, model_name):\",\n",
                "                \"    plt.figure(figsize = (10, 10))\",\n",
                "                \"    plt.scatter(y_true, y_pred)   \",\n",
                "                \"    p1 = max(max(y_pred), max(y_true))\",\n",
                "                \"    p2 = min(min(y_pred), min(y_pred))\",\n",
                "                \"    plt.plot([p1, p2], [p1, p2], 'b-')\",\n",
                "                \"    plt.xlabel('Observed ' + WQPu, fontsize=15, color='black')\",\n",
                "                \"    plt.ylabel('Predicted ' + WQPu, fontsize=15, color='black')\",\n",
                "                \"    plt.axis('equal')\",\n",
                "                \"    plt.grid(linestyle=':', linewidth=1)\",\n",
                "                \"    plt.savefig('n/'+ WQPn +'_SP_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\",\n",
                "                \"    plt.close()\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-f9fdf78c\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def metrics_time_series(y_true, y_pred):\",\n",
                "                \"    mae = round         (mean_absolute_error(y_true, y_pred), 7)\",\n",
                "                \"    mse = round         (mean_squared_error(y_true, y_pred), 7)\",\n",
                "                \"    rmse= round         (np.sqrt(mean_squared_error(y_true, y_pred)), 7)\",\n",
                "                \"    mape= round         (mean_absolute_percentage_error(y_true, y_pred), 7)\",\n",
                "                \"   \",\n",
                "                \"    return mae, mse, rmse, mape \"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-2bba3676\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def plotting_predictions(dataset, look_back, train_predict,  test_predict,DLname):\",\n",
                "                \"    np.random.seed(42)\",\n",
                "                \"    # shift train predictions for plotting\",\n",
                "                \"    trainPredictPlot = np.empty_like(dataset)\",\n",
                "                \"    trainPredictPlot[:, :] = np.nan\",\n",
                "                \"    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\",\n",
                "                \"    # shift test predictions for plotting\",\n",
                "                \"    testPredictPlot = np.empty_like(dataset)\",\n",
                "                \"    testPredictPlot[:, :] = np.nan\",\n",
                "                \"    testPredictPlot[len(train_predict)+(look_back*2)+1:len(dataset)-1, :] = test_predict\",\n",
                "                \"    # plot baseline and predictions\",\n",
                "                \"    plt.figure(figsize=(10,6))\",\n",
                "                \"    plt.plot(scaler.inverse_transform(dataset[wz:]), 'b', label=\\\"True Data\\\")\",\n",
                "                \"    plt.plot(trainPredictPlot[wz:], 'r', label='Train')\",\n",
                "                \"    plt.plot(testPredictPlot[wz:], 'g', label=\\\"Prediction\\\")\",\n",
                "                \"    plt.ylabel(WQPu, fontsize=15)\",\n",
                "                \"    plt.xlabel('Days', fontsize=15)\",\n",
                "                \"    plt.grid(linestyle=':', linewidth=1)\",\n",
                "                \"    plt.legend()\",\n",
                "                \"    #plt.savefig(\\\"'1'+model.pdf\\\", dpi=300)\",\n",
                "                \"    plt.title('True future vs prediction for ' + DLname)\",\n",
                "                \"    plt.savefig('n/'+ WQPn +'_pred'+ DLname + l + s + e + w + b + o + d +'.pdf', dpi=300)\",\n",
                "                \"    plt.close()\",\n",
                "                \"    return    \"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-911a4e2a\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def plot_loss (model_name):\",\n",
                "                \"    fig = plt.figure(figsize = (10, 6))\",\n",
                "                \"    plt.plot(history.history['loss'])\",\n",
                "                \"    plt.plot(history.history['val_loss'])\",\n",
                "                \"    plt.title('Model Train vs Validation Loss for ' + model_name)\",\n",
                "                \"    plt.ylabel('Loss', fontsize=15)\",\n",
                "                \"    plt.xlabel('epoch', fontsize=15)\",\n",
                "                \"    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\",\n",
                "                \"    plt.grid(linestyle=':', linewidth=1)\",\n",
                "                \"    plt.savefig('n/'+ WQPn +'_loss_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\",\n",
                "                \"    plt.close()\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-c336df49\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learning1(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"LSTM\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"\",\n",
                "                \"    model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.LSTM(32, input_shape=(look_back, 1)),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"      ])\",\n",
                "                \"      \",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"   ##model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"    \",\n",
                "                \"history, x_train_predict_lstm, y_train_lstm,x_test_predict_lstm, y_test_lstm, name, res= time_series_deep_learning1(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-4b7531c5\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learning2(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"GRU\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    \",\n",
                "                \"    model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.GRU(32, input_shape=(look_back, 1)),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)\",\n",
                "                \"    ])\",\n",
                "                \"    \",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"   #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_gru, y_train_gru, x_test_predict_gru, y_test_gru, name, res= time_series_deep_learning2(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-2f16be14\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"from keras.layers import *\",\n",
                "                \"from keras.models import *\",\n",
                "                \"from keras import backend as K\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-7ff8c90b\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"# Add attention layer to the deep learning network\",\n",
                "                \"class attention(Layer):\",\n",
                "                \"    def __init__(self,**kwargs):\",\n",
                "                \"        super(attention,self).__init__(**kwargs)\",\n",
                "                \"\",\n",
                "                \"    def build(self,input_shape):\",\n",
                "                \"        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), initializer='random_normal', trainable=True)\",\n",
                "                \"        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), initializer='zeros', trainable=True)        \",\n",
                "                \"        super(attention, self).build(input_shape)\",\n",
                "                \"\",\n",
                "                \"    def call(self,x):\",\n",
                "                \"        # Alignment scores. Pass them through tanh function\",\n",
                "                \"        e = K.tanh(K.dot(x,self.W)+self.b)\",\n",
                "                \"        # Remove dimension of size 1\",\n",
                "                \"        e = K.squeeze(e, axis=-1)   \",\n",
                "                \"        # Compute the weights\",\n",
                "                \"        alpha = K.softmax(e)\",\n",
                "                \"        # Reshape to tensorFlow format\",\n",
                "                \"        alpha = K.expand_dims(alpha, axis=-1)\",\n",
                "                \"        # Compute the context vector\",\n",
                "                \"        context = x * alpha\",\n",
                "                \"        context = K.sum(context, axis=1)\",\n",
                "                \"        return context\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-b8feb052\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learningBiLSTM(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"BiLSTM\\\"\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    \",\n",
                "                \"    model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.Bidirectional(LSTM(32,input_shape=(look_back, 1))),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"     ])\",\n",
                "                \"      \",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_BiLSTM, y_train_BiLSTM,x_test_predict_BiLSTM, y_test_BiLSTM, name, res= time_series_deep_learningBiLSTM(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-427e8a55\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learningBiGRU(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"BiGRU\\\"\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    \",\n",
                "                \"    model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.Bidirectional(GRU(32, input_shape=(look_back, 1))),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"     ])\",\n",
                "                \"      \",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_BiGRU, y_train_BiGRU,x_test_predict_BiGRU, y_test_BiGRU, name, res= time_series_deep_learningBiGRU(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-d49a53f4\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learning6(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"LSTM_Att\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"\",\n",
                "                \"    hidden_units = 2\",\n",
                "                \"    input_shape=(look_back, 1)\",\n",
                "                \"    x=Input(shape=input_shape)\",\n",
                "                \"\",\n",
                "                \"    LSTM_model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.LSTM(32, return_sequences=True, activation ='relu'),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"      ])(x)\",\n",
                "                \"    \",\n",
                "                \"    attention_layer = attention()(LSTM_model)\",\n",
                "                \"    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\",\n",
                "                \"    model=Model(x,outputs)\",\n",
                "                \"\",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"   ##model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"    \",\n",
                "                \"history, x_train_predict_lstm_Att, y_train_lstm_Att,x_test_predict_lstm_Att, y_test_lstm_Att, name, res= time_series_deep_learning6(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-1a582e00\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learning7(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"GRU_Att\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"\",\n",
                "                \"    hidden_units = 2\",\n",
                "                \"    input_shape=(look_back, 1)\",\n",
                "                \"    x=Input(shape=input_shape)\",\n",
                "                \"\",\n",
                "                \"    GRU_model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.GRU(32, return_sequences=True, activation ='relu'),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"    tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"      ])(x)\",\n",
                "                \"    \",\n",
                "                \"    attention_layer = attention()(GRU_model)\",\n",
                "                \"    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\",\n",
                "                \"    model=Model(x,outputs)\",\n",
                "                \"\",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"   #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_gru_Att, y_train_gru_Att, x_test_predict_gru_Att, y_test_gru_Att, name, res= time_series_deep_learning7(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-5c74e7ff\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learningBiLSTM_Att(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"Bi-LSTM_Att\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"\",\n",
                "                \"    hidden_units = 2\",\n",
                "                \"    input_shape=(look_back, 1)\",\n",
                "                \"    x=Input(shape=input_shape)\",\n",
                "                \"\",\n",
                "                \"    BiLSTM_model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.Bidirectional(LSTM(32, return_sequences=True)),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"   #tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"      ])(x)\",\n",
                "                \"    \",\n",
                "                \"    attention_layer = attention()(BiLSTM_model)\",\n",
                "                \"    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\",\n",
                "                \"    model=Model(x,outputs)\",\n",
                "                \"\",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"\",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_Bilstm_Att, y_train_Bilstm_Att,x_test_predict_Bilstm_Att, y_test_Bilstm_Att, name, res= time_series_deep_learningBiLSTM_Att(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)    \",\n",
                "                \"\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-343f4e55\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"def time_series_deep_learningBiGRU_Att(x_train, y_train, x_test, y_test):\",\n",
                "                \"    tf.keras.backend.clear_session()\",\n",
                "                \"    tf.random.set_seed(51)\",\n",
                "                \"    name = \\\"Bi-GRU_Att\\\"\",\n",
                "                \"    # instance of a Sequential model\",\n",
                "                \"    ST = time.time()\",\n",
                "                \"\",\n",
                "                \"    hidden_units = 2\",\n",
                "                \"    input_shape=(look_back, 1)\",\n",
                "                \"    x=Input(shape=input_shape)\",\n",
                "                \"\",\n",
                "                \"    BiGRU_model = tf.keras.models.Sequential([\",\n",
                "                \"    tf.keras.layers.Bidirectional(GRU(32, return_sequences=True)),\",\n",
                "                \"    tf.keras.layers.Dense(30, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(10, activation=\\\"relu\\\"),\",\n",
                "                \"    tf.keras.layers.Dense(1),\",\n",
                "                \"   #tf.keras.layers.Lambda(lambda x: x * 400)  \",\n",
                "                \"      ])(x)\",\n",
                "                \"    \",\n",
                "                \"    attention_layer = attention()(BiGRU_model)\",\n",
                "                \"    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\",\n",
                "                \"    model=Model(x,outputs)\",\n",
                "                \"\",\n",
                "                \"    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\",\n",
                "                \"    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    train_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    # make predictions\",\n",
                "                \"    train_predict = model.predict(x_train)\",\n",
                "                \"    \",\n",
                "                \"    ST = time.time()\",\n",
                "                \"    test_predict = model.predict(x_test)\",\n",
                "                \"    ET = time.time()\",\n",
                "                \"    test_time = ET - ST\",\n",
                "                \"    \",\n",
                "                \"    #model.summary ()\",\n",
                "                \"    \",\n",
                "                \"    # invert predictions\",\n",
                "                \"    train_predict = scaler.inverse_transform(train_predict)\",\n",
                "                \"    train_y = scaler.inverse_transform(y_train)\",\n",
                "                \"    test_predict = scaler.inverse_transform(test_predict)\",\n",
                "                \"    test_y = scaler.inverse_transform(y_test)    \",\n",
                "                \"\",\n",
                "                \"    # compute the metrics \",\n",
                "                \"    #print(\\\"Train\\\")\",\n",
                "                \"    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\",\n",
                "                \"    #print(\\\"Test\\\")\",\n",
                "                \"    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\",\n",
                "                \"      \",\n",
                "                \"    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\\\"Name\\\", \\\"mae_train\\\", \\\"mse_train\\\",\\\"rmse_train\\\", \\\"mape_train\\\", \\\"Train_time_s\\\",\\\"mae_test\\\", \\\"mse_test\\\", \\\"rmse_test\\\", \\\"mape_test\\\", \\\"Test_time_s\\\"]).T\",\n",
                "                \"\",\n",
                "                \"history, x_train_predict_Bigru_Att, y_train_Bigru_Att, x_test_predict_Bigru_Att, y_test_Bigru_Att, name, res= time_series_deep_learningBiGRU_Att(train_x, train_y, test_x, test_y)\",\n",
                "                \"plot_loss (name)\",\n",
                "                \"df_results = df_results.append(res)\"\n",
                "            ]\n",
                "        },\n",
                "        {\n",
                "            \"cell_type\": \"code\",\n",
                "            \"id\": \"#VSC-45343faa\",\n",
                "            \"metadata\": {\n",
                "                \"language\": \"python\"\n",
                "            },\n",
                "            \"source\": [\n",
                "                \"#b : blue.  g : green.  r : red.    c : cyan.   m : magenta.    y : yellow. k : black.  w : white.\",\n",
                "                \"#look_back = 20\",\n",
                "                \"testPredictPlot11 = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot11[:, :] = np.nan\",\n",
                "                \"testPredictPlot11[0:Lgr, :] = x_test_predict_lstm\",\n",
                "                \"testPredictPlot12 = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot12[:, :] = np.nan\",\n",
                "                \"testPredictPlot12[0:Lgr, :] = x_test_predict_BiLSTM\",\n",
                "                \"testPredictPlot13 = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot13[:, :] = np.nan\",\n",
                "                \"testPredictPlot13[0:Lgr, :] = x_test_predict_lstm_Att\",\n",
                "                \"testPredictPlot14 = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot14[:, :] = np.nan\",\n",
                "                \"testPredictPlot14[0:Lgr, :] = x_test_predict_Bilstm_Att\",\n",
                "                \"\",\n",
                "                \"testPredictPlot11g = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot11g[:, :] = np.nan\",\n",
                "                \"testPredictPlot11g[0:Lgr, :] = x_test_predict_gru\",\n",
                "                \"testPredictPlot12g = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot12g[:, :] = np.nan\",\n",
                "                \"testPredictPlot12g[0:Lgr, :] = x_test_predict_BiGRU\",\n",
                "                \"testPredictPlot13g = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot13g[:, :] = np.nan\",\n",
                "                \"testPredictPlot13g[0:Lgr, :] = x_test_predict_gru_Att\",\n",
                "                \"testPredictPlot14g = np.empty_like(dataset)\",\n",
                "                \"testPredictPlot14g[:, :] = np.nan\",\n",
                "                \"testPredictPlot14g[0:Lgr, :] = x_test_predict_Bigru_Att\",\n",
                "                \"\",\n",
                "                \"plt.figure()\",\n",
                "                \"plt.plot(scaler.inverse_transform(dataset[dLgr:]), 'k', label=\\\"True Data\\\")\",\n",
                "                \"plt.plot(testPredictPlot11[:], label=\\\"LSTM Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot11g[:], label=\\\"GRU Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot12[:], label=\\\"BiLSTM Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot12g[:], label=\\\"BiGRU Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot13[:], label=\\\"Att-LSTM Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot13g[:], label=\\\"Att-GRU Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot14[:], label=\\\"Att-BiLSTM Prediction\\\")\",\n",
                "                \"plt.plot(testPredictPlot14g[:], label=\\\"Att-BiGRU Prediction\\\")\",\n",
                "                \"\",\n",
                "                \"plt.ylabel(WQPu, fontsize=12)\",\n",
                "                \"plt.xlabel('Days', fontsize=12)\",\n",
                "                \"plt.grid(linestyle=':', linewidth=1)\",\n",
                "                \"plt.legend()\",\n",
                "                \"plt.savefig('n/'+ WQPn +'_Comp_of_pred'+ l + s + e + w + b + o + d +'.pdf', dpi=300)\",\n",
                "                \"plt.close()\"\n",
                "            ]\n",
                "        }\n",
                "    ]\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "ae6c3974-2605-4dc8-862c-31a7ddde9e87",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "x_train = df[WQP].dropna()\n",
                "print(WQP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_results = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "8051d4b3-abf1-4e6c-aa73-7d5365a3aee4",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# convert an array of values into a dataset matrix\n",
                "def create_dataset(values, look_back):\n",
                "    np.random.seed(42)\n",
                "     # set empty lists \n",
                "    _x, _y = [], []\n",
                "    for i in range(len(values)-look_back-1):\n",
                "        a = values[i:(i+look_back)]      # stack a list of values\n",
                "        _x.append(a)                        # set x\n",
                "        _y.append(values[i + look_back]) # set y\n",
                "    return np.array(_x), np.array(_y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "aede10c7-45c0-4987-88cb-5301e2872f22",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "num = 2\n",
                "values = df[WQP].values\n",
                "# normalize the dataset\n",
                "scaler = MinMaxScaler(feature_range=(0, 1))\n",
                "dataset = scaler.fit_transform(values[~np.isnan(values)].reshape(-1, 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "67faac73-f14a-4be0-9b5f-b119d3f55713"
            },
            "outputs": [],
            "source": [
                "# split into train and test sets\n",
                "train_size = int(len(dataset) * split)\n",
                "test_size = len(dataset) - train_size\n",
                "train, test = dataset[:train_size], dataset[train_size:]\n",
                "# reshape into X=t and Y=t+1\n",
                "#look_back = 20\n",
                "train_x, train_y = create_dataset(train, look_back)\n",
                "test_x, test_y = create_dataset(test, look_back)\n",
                "# reshape input to be [samples, time steps, features]\n",
                "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
                "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Lgr = test_size-wz-1\n",
                "dLgr = train_size+wz+1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "042e2ede-eed7-4c30-ae46-cd473460574a",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "   def scatter_plot(y_true, y_pred, model_name):\n",
                "    plt.figure(figsize = (10, 10))\n",
                "    plt.scatter(y_true, y_pred)   \n",
                "    p1 = max(max(y_pred), max(y_true))\n",
                "    p2 = min(min(y_pred), min(y_pred))\n",
                "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
                "    plt.xlabel('Observed ' + WQPu, fontsize=15, color='black')\n",
                "    plt.ylabel('Predicted ' + WQPu, fontsize=15, color='black')\n",
                "    plt.axis('equal')\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.savefig('n/'+ WQPn +'_SP_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e5ff2aa0-d172-469a-a1ff-91109b8a6416",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def metrics_time_series(y_true, y_pred):\n",
                "    mae = round         (mean_absolute_error(y_true, y_pred), 7)\n",
                "    mse = round         (mean_squared_error(y_true, y_pred), 7)\n",
                "    rmse= round         (np.sqrt(mean_squared_error(y_true, y_pred)), 7)\n",
                "    mape= round         (mean_absolute_percentage_error(y_true, y_pred), 7)\n",
                "   \n",
                "    return mae, mse, rmse, mape "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "ce72aaa2-a9d5-4ed0-9547-ecbe9427137c",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plotting_predictions(dataset, look_back, train_predict,  test_predict,DLname):\n",
                "    np.random.seed(42)\n",
                "    # shift train predictions for plotting\n",
                "    trainPredictPlot = np.empty_like(dataset)\n",
                "    trainPredictPlot[:, :] = np.nan\n",
                "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
                "    # shift test predictions for plotting\n",
                "    testPredictPlot = np.empty_like(dataset)\n",
                "    testPredictPlot[:, :] = np.nan\n",
                "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(dataset)-1, :] = test_predict\n",
                "    # plot baseline and predictions\n",
                "    plt.figure(figsize=(10,6))\n",
                "    plt.plot(scaler.inverse_transform(dataset[wz:]), 'b', label=\"True Data\")\n",
                "    plt.plot(trainPredictPlot[wz:], 'r', label='Train')\n",
                "    plt.plot(testPredictPlot[wz:], 'g', label=\"Prediction\")\n",
                "    plt.ylabel(WQPu, fontsize=15)\n",
                "    plt.xlabel('Days', fontsize=15)\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.legend()\n",
                "    #plt.savefig(\"'1'+model.pdf\", dpi=300)\n",
                "    plt.title('True future vs prediction for ' + DLname)\n",
                "    plt.savefig('n/'+ WQPn +'_pred'+ DLname + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()\n",
                "    return    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "743f1e9c-1b87-4d93-b3fb-0179649fe837",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plot_loss (model_name):\n",
                "    fig = plt.figure(figsize = (10, 6))\n",
                "    plt.plot(history.history['loss'])\n",
                "    plt.plot(history.history['val_loss'])\n",
                "    plt.title('Model Train vs Validation Loss for ' + model_name)\n",
                "    plt.ylabel('Loss', fontsize=15)\n",
                "    plt.xlabel('epoch', fontsize=15)\n",
                "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.savefig('n/'+ WQPn +'_loss_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "b159efc0-592b-4d84-ad18-44223988677e",
                "tags": []
            },
            "outputs": [],
            "source": [
                "def time_series_deep_learning1(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"LSTM\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.LSTM(32, input_shape=(look_back, 1)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   ##model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "    \n",
                "history, x_train_predict_lstm, y_train_lstm,x_test_predict_lstm, y_test_lstm, name, res= time_series_deep_learning1(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning2(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"GRU\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.GRU(32, input_shape=(look_back, 1)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
                "    ])\n",
                "    \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_gru, y_train_gru, x_test_predict_gru, y_test_gru, name, res= time_series_deep_learning2(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.layers import *\n",
                "from keras.models import *\n",
                "from keras import backend as K"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add attention layer to the deep learning network\n",
                "class attention(Layer):\n",
                "    def __init__(self,**kwargs):\n",
                "        super(attention,self).__init__(**kwargs)\n",
                "\n",
                "    def build(self,input_shape):\n",
                "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), initializer='random_normal', trainable=True)\n",
                "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), initializer='zeros', trainable=True)        \n",
                "        super(attention, self).build(input_shape)\n",
                "\n",
                "    def call(self,x):\n",
                "        # Alignment scores. Pass them through tanh function\n",
                "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
                "        # Remove dimension of size 1\n",
                "        e = K.squeeze(e, axis=-1)   \n",
                "        # Compute the weights\n",
                "        alpha = K.softmax(e)\n",
                "        # Reshape to tensorFlow format\n",
                "        alpha = K.expand_dims(alpha, axis=-1)\n",
                "        # Compute the context vector\n",
                "        context = x * alpha\n",
                "        context = K.sum(context, axis=1)\n",
                "        return context"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiLSTM(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"BiLSTM\"\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(LSTM(32,input_shape=(look_back, 1))),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "     ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_BiLSTM, y_train_BiLSTM,x_test_predict_BiLSTM, y_test_BiLSTM, name, res= time_series_deep_learningBiLSTM(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiGRU(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"BiGRU\"\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(GRU(32, input_shape=(look_back, 1))),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "     ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_BiGRU, y_train_BiGRU,x_test_predict_BiGRU, y_test_BiGRU, name, res= time_series_deep_learningBiGRU(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning6(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"LSTM_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    LSTM_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.LSTM(32, return_sequences=True, activation ='relu'),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(LSTM_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   ##model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "    \n",
                "history, x_train_predict_lstm_Att, y_train_lstm_Att,x_test_predict_lstm_Att, y_test_lstm_Att, name, res= time_series_deep_learning6(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning7(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"GRU_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    GRU_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.GRU(32, return_sequences=True, activation ='relu'),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(GRU_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "    \n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_gru_Att, y_train_gru_Att, x_test_predict_gru_Att, y_test_gru_Att, name, res= time_series_deep_learning7(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiLSTM_Att(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"Bi-LSTM_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    BiLSTM_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(LSTM(32, return_sequences=True)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "   #tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(BiLSTM_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_Bilstm_Att, y_train_Bilstm_Att,x_test_predict_Bilstm_Att, y_test_Bilstm_Att, name, res= time_series_deep_learningBiLSTM_Att(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiGRU_Att(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"Bi-GRU_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    BiGRU_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(GRU(32, return_sequences=True)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "   #tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(BiGRU_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "    \n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_Bigru_Att, y_train_Bigru_Att, x_test_predict_Bigru_Att, y_test_Bigru_Att, name, res= time_series_deep_learningBiGRU_Att(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#b : blue.  g : green.  r : red.    c : cyan.   m : magenta.    y : yellow. k : black.  w : white.\n",
                "#look_back = 20\n",
                "testPredictPlot11 = np.empty_like(dataset)\n",
                "testPredictPlot11[:, :] = np.nan\n",
                "testPredictPlot11[0:Lgr, :] = x_test_predict_lstm\n",
                "testPredictPlot12 = np.empty_like(dataset)\n",
                "testPredictPlot12[:, :] = np.nan\n",
                "testPredictPlot12[0:Lgr, :] = x_test_predict_BiLSTM\n",
                "testPredictPlot13 = np.empty_like(dataset)\n",
                "testPredictPlot13[:, :] = np.nan\n",
                "testPredictPlot13[0:Lgr, :] = x_test_predict_lstm_Att\n",
                "testPredictPlot14 = np.empty_like(dataset)\n",
                "testPredictPlot14[:, :] = np.nan\n",
                "testPredictPlot14[0:Lgr, :] = x_test_predict_Bilstm_Att\n",
                "\n",
                "testPredictPlot11g = np.empty_like(dataset)\n",
                "testPredictPlot11g[:, :] = np.nan\n",
                "testPredictPlot11g[0:Lgr, :] = x_test_predict_gru\n",
                "testPredictPlot12g = np.empty_like(dataset)\n",
                "testPredictPlot12g[:, :] = np.nan\n",
                "testPredictPlot12g[0:Lgr, :] = x_test_predict_BiGRU\n",
                "testPredictPlot13g = np.empty_like(dataset)\n",
                "testPredictPlot13g[:, :] = np.nan\n",
                "testPredictPlot13g[0:Lgr, :] = x_test_predict_gru_Att\n",
                "testPredictPlot14g = np.empty_like(dataset)\n",
                "testPredictPlot14g[:, :] = np.nan\n",
                "testPredictPlot14g[0:Lgr, :] = x_test_predict_Bigru_Att\n",
                "\n",
                "plt.figure()\n",
                "plt.plot(scaler.inverse_transform(dataset[dLgr:]), 'k', label=\"True Data\")\n",
                "plt.plot(testPredictPlot11[:], label=\"LSTM Prediction\")\n",
                "plt.plot(testPredictPlot11g[:], label=\"GRU Prediction\")\n",
                "plt.plot(testPredictPlot12[:], label=\"BiLSTM Prediction\")\n",
                "plt.plot(testPredictPlot12g[:], label=\"BiGRU Prediction\")\n",
                "plt.plot(testPredictPlot13[:], label=\"Att-LSTM Prediction\")\n",
                "plt.plot(testPredictPlot13g[:], label=\"Att-GRU Prediction\")\n",
                "plt.plot(testPredictPlot14[:], label=\"Att-BiLSTM Prediction\")\n",
                "plt.plot(testPredictPlot14g[:], label=\"Att-BiGRU Prediction\")\n",
                "\n",
                "plt.ylabel(WQPu, fontsize=12)\n",
                "plt.xlabel('Days', fontsize=12)\n",
                "plt.grid(linestyle=':', linewidth=1)\n",
                "plt.legend()\n",
                "plt.savefig('n/'+ WQPn +'_Comp_of_pred'+ l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "plt.close()"
            ]
        }
    ],
    "metadata": {
        "extensions": {
            "azuredatastudio": {
                "version": 1,
                "views": []
            }
        },
        "interpreter": {
            "hash": "3d9542168a597b2d0444e6c29e198981e2db3768152cab7dd0ba762f50929013"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
