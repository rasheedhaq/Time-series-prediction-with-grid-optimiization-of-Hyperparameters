{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "ae6c3974-2605-4dc8-862c-31a7ddde9e87",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "x_train = df[WQP].dropna()\n",
                "print(WQP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_results = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "8051d4b3-abf1-4e6c-aa73-7d5365a3aee4",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# convert an array of values into a dataset matrix\n",
                "def create_dataset(values, look_back):\n",
                "    np.random.seed(42)\n",
                "     # set empty lists \n",
                "    _x, _y = [], []\n",
                "    for i in range(len(values)-look_back-1):\n",
                "        a = values[i:(i+look_back)]      # stack a list of values\n",
                "        _x.append(a)                        # set x\n",
                "        _y.append(values[i + look_back]) # set y\n",
                "    return np.array(_x), np.array(_y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "aede10c7-45c0-4987-88cb-5301e2872f22",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "num = 2\n",
                "values = df[WQP].values\n",
                "# normalize the dataset\n",
                "scaler = MinMaxScaler(feature_range=(0, 1))\n",
                "dataset = scaler.fit_transform(values[~np.isnan(values)].reshape(-1, 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "67faac73-f14a-4be0-9b5f-b119d3f55713"
            },
            "outputs": [],
            "source": [
                "# split into train and test sets\n",
                "train_size = int(len(dataset) * split)\n",
                "test_size = len(dataset) - train_size\n",
                "train, test = dataset[:train_size], dataset[train_size:]\n",
                "# reshape into X=t and Y=t+1\n",
                "#look_back = 20\n",
                "train_x, train_y = create_dataset(train, look_back)\n",
                "test_x, test_y = create_dataset(test, look_back)\n",
                "# reshape input to be [samples, time steps, features]\n",
                "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
                "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Lgr = test_size-wz-1\n",
                "dLgr = train_size+wz+1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "042e2ede-eed7-4c30-ae46-cd473460574a",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "   def scatter_plot(y_true, y_pred, model_name):\n",
                "    plt.figure(figsize = (10, 10))\n",
                "    plt.scatter(y_true, y_pred)   \n",
                "    p1 = max(max(y_pred), max(y_true))\n",
                "    p2 = min(min(y_pred), min(y_pred))\n",
                "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
                "    plt.xlabel('Observed ' + WQPu, fontsize=15, color='black')\n",
                "    plt.ylabel('Predicted ' + WQPu, fontsize=15, color='black')\n",
                "    plt.axis('equal')\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.savefig('n/'+ WQPn +'_SP_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e5ff2aa0-d172-469a-a1ff-91109b8a6416",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def metrics_time_series(y_true, y_pred):\n",
                "    mae = round         (mean_absolute_error(y_true, y_pred), 7)\n",
                "    mse = round         (mean_squared_error(y_true, y_pred), 7)\n",
                "    rmse= round         (np.sqrt(mean_squared_error(y_true, y_pred)), 7)\n",
                "    mape= round         (mean_absolute_percentage_error(y_true, y_pred), 7)\n",
                "   \n",
                "    return mae, mse, rmse, mape "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "ce72aaa2-a9d5-4ed0-9547-ecbe9427137c",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plotting_predictions(dataset, look_back, train_predict,  test_predict,DLname):\n",
                "    np.random.seed(42)\n",
                "    # shift train predictions for plotting\n",
                "    trainPredictPlot = np.empty_like(dataset)\n",
                "    trainPredictPlot[:, :] = np.nan\n",
                "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
                "    # shift test predictions for plotting\n",
                "    testPredictPlot = np.empty_like(dataset)\n",
                "    testPredictPlot[:, :] = np.nan\n",
                "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(dataset)-1, :] = test_predict\n",
                "    # plot baseline and predictions\n",
                "    plt.figure(figsize=(10,6))\n",
                "    plt.plot(scaler.inverse_transform(dataset[wz:]), 'b', label=\"True Data\")\n",
                "    plt.plot(trainPredictPlot[wz:], 'r', label='Train')\n",
                "    plt.plot(testPredictPlot[wz:], 'g', label=\"Prediction\")\n",
                "    plt.ylabel(WQPu, fontsize=15)\n",
                "    plt.xlabel('Days', fontsize=15)\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.legend()\n",
                "    #plt.savefig(\"'1'+model.pdf\", dpi=300)\n",
                "    plt.title('True future vs prediction for ' + DLname)\n",
                "    plt.savefig('n/'+ WQPn +'_pred'+ DLname + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()\n",
                "    return    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "743f1e9c-1b87-4d93-b3fb-0179649fe837",
                "extensions": {
                    "azuredatastudio": {
                        "views": []
                    }
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plot_loss (model_name):\n",
                "    fig = plt.figure(figsize = (10, 6))\n",
                "    plt.plot(history.history['loss'])\n",
                "    plt.plot(history.history['val_loss'])\n",
                "    plt.title('Model Train vs Validation Loss for ' + model_name)\n",
                "    plt.ylabel('Loss', fontsize=15)\n",
                "    plt.xlabel('epoch', fontsize=15)\n",
                "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
                "    plt.grid(linestyle=':', linewidth=1)\n",
                "    plt.savefig('n/'+ WQPn +'_loss_'+ model_name + l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "b159efc0-592b-4d84-ad18-44223988677e",
                "tags": []
            },
            "outputs": [],
            "source": [
                "def time_series_deep_learning1(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"LSTM\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.LSTM(32, input_shape=(look_back, 1)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   ##model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "    \n",
                "history, x_train_predict_lstm, y_train_lstm,x_test_predict_lstm, y_test_lstm, name, res= time_series_deep_learning1(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning2(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"GRU\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.GRU(32, input_shape=(look_back, 1)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
                "    ])\n",
                "    \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_gru, y_train_gru, x_test_predict_gru, y_test_gru, name, res= time_series_deep_learning2(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.layers import *\n",
                "from keras.models import *\n",
                "from keras import backend as K"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add attention layer to the deep learning network\n",
                "class attention(Layer):\n",
                "    def __init__(self,**kwargs):\n",
                "        super(attention,self).__init__(**kwargs)\n",
                "\n",
                "    def build(self,input_shape):\n",
                "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), initializer='random_normal', trainable=True)\n",
                "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), initializer='zeros', trainable=True)        \n",
                "        super(attention, self).build(input_shape)\n",
                "\n",
                "    def call(self,x):\n",
                "        # Alignment scores. Pass them through tanh function\n",
                "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
                "        # Remove dimension of size 1\n",
                "        e = K.squeeze(e, axis=-1)   \n",
                "        # Compute the weights\n",
                "        alpha = K.softmax(e)\n",
                "        # Reshape to tensorFlow format\n",
                "        alpha = K.expand_dims(alpha, axis=-1)\n",
                "        # Compute the context vector\n",
                "        context = x * alpha\n",
                "        context = K.sum(context, axis=1)\n",
                "        return context"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiLSTM(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"BiLSTM\"\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(LSTM(32,input_shape=(look_back, 1))),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "     ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_BiLSTM, y_train_BiLSTM,x_test_predict_BiLSTM, y_test_BiLSTM, name, res= time_series_deep_learningBiLSTM(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiGRU(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"BiGRU\"\n",
                "    ST = time.time()\n",
                "    \n",
                "    model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(GRU(32, input_shape=(look_back, 1))),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "     ])\n",
                "      \n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_BiGRU, y_train_BiGRU,x_test_predict_BiGRU, y_test_BiGRU, name, res= time_series_deep_learningBiGRU(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning6(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"LSTM_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    LSTM_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.LSTM(32, return_sequences=True, activation ='relu'),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(LSTM_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   ##model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "    \n",
                "history, x_train_predict_lstm_Att, y_train_lstm_Att,x_test_predict_lstm_Att, y_test_lstm_Att, name, res= time_series_deep_learning6(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learning7(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"GRU_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    GRU_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.GRU(32, return_sequences=True, activation ='relu'),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "    tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(GRU_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "    \n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "   #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_gru_Att, y_train_gru_Att, x_test_predict_gru_Att, y_test_gru_Att, name, res= time_series_deep_learning7(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiLSTM_Att(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"Bi-LSTM_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    BiLSTM_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(LSTM(32, return_sequences=True)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "   #tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(BiLSTM_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "\n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_Bilstm_Att, y_train_Bilstm_Att,x_test_predict_Bilstm_Att, y_test_Bilstm_Att, name, res= time_series_deep_learningBiLSTM_Att(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def time_series_deep_learningBiGRU_Att(x_train, y_train, x_test, y_test):\n",
                "    tf.keras.backend.clear_session()\n",
                "    tf.random.set_seed(51)\n",
                "    name = \"Bi-GRU_Att\"\n",
                "    # instance of a Sequential model\n",
                "    ST = time.time()\n",
                "\n",
                "    hidden_units = 2\n",
                "    input_shape=(look_back, 1)\n",
                "    x=Input(shape=input_shape)\n",
                "\n",
                "    BiGRU_model = tf.keras.models.Sequential([\n",
                "    tf.keras.layers.Bidirectional(GRU(32, return_sequences=True)),\n",
                "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
                "    tf.keras.layers.Dense(1),\n",
                "   #tf.keras.layers.Lambda(lambda x: x * 400)  \n",
                "      ])(x)\n",
                "    \n",
                "    attention_layer = attention()(BiGRU_model)\n",
                "    outputs=Dense(1, trainable=True, activation='tanh')(attention_layer)\n",
                "    model=Model(x,outputs)\n",
                "\n",
                "    model.compile(loss='mean_squared_error', optimizer= opt, metrics=['accuracy'])\n",
                "    history=model.fit(x_train, y_train, epochs=epno, validation_split = 0.2, batch_size=bz, verbose=0)\n",
                "    ET = time.time()\n",
                "    train_time = ET - ST\n",
                "    \n",
                "    # make predictions\n",
                "    train_predict = model.predict(x_train)\n",
                "    \n",
                "    ST = time.time()\n",
                "    test_predict = model.predict(x_test)\n",
                "    ET = time.time()\n",
                "    test_time = ET - ST\n",
                "    \n",
                "    #model.summary ()\n",
                "    \n",
                "    # invert predictions\n",
                "    train_predict = scaler.inverse_transform(train_predict)\n",
                "    train_y = scaler.inverse_transform(y_train)\n",
                "    test_predict = scaler.inverse_transform(test_predict)\n",
                "    test_y = scaler.inverse_transform(y_test)    \n",
                "\n",
                "    # compute the metrics \n",
                "    #print(\"Train\")\n",
                "    mae_train, mse_train, rmse_train, mape_train = metrics_time_series( train_y, train_predict)\n",
                "    #print(\"Test\")\n",
                "    mae_test, mse_test, rmse_test, mape_test = metrics_time_series( test_y, test_predict)\n",
                "      \n",
                "    return history,train_predict, train_y, test_predict, test_y, name, pd.DataFrame([name, mae_train, mse_train, rmse_train, mape_train, train_time, mae_test, mse_test, rmse_test, mape_test,test_time], index= [\"Name\", \"mae_train\", \"mse_train\",\"rmse_train\", \"mape_train\", \"Train_time_s\",\"mae_test\", \"mse_test\", \"rmse_test\", \"mape_test\", \"Test_time_s\"]).T\n",
                "\n",
                "history, x_train_predict_Bigru_Att, y_train_Bigru_Att, x_test_predict_Bigru_Att, y_test_Bigru_Att, name, res= time_series_deep_learningBiGRU_Att(train_x, train_y, test_x, test_y)\n",
                "plot_loss (name)\n",
                "df_results = df_results.append(res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#b : blue.  g : green.  r : red.    c : cyan.   m : magenta.    y : yellow. k : black.  w : white.\n",
                "#look_back = 20\n",
                "testPredictPlot11 = np.empty_like(dataset)\n",
                "testPredictPlot11[:, :] = np.nan\n",
                "testPredictPlot11[0:Lgr, :] = x_test_predict_lstm\n",
                "testPredictPlot12 = np.empty_like(dataset)\n",
                "testPredictPlot12[:, :] = np.nan\n",
                "testPredictPlot12[0:Lgr, :] = x_test_predict_BiLSTM\n",
                "testPredictPlot13 = np.empty_like(dataset)\n",
                "testPredictPlot13[:, :] = np.nan\n",
                "testPredictPlot13[0:Lgr, :] = x_test_predict_lstm_Att\n",
                "testPredictPlot14 = np.empty_like(dataset)\n",
                "testPredictPlot14[:, :] = np.nan\n",
                "testPredictPlot14[0:Lgr, :] = x_test_predict_Bilstm_Att\n",
                "\n",
                "testPredictPlot11g = np.empty_like(dataset)\n",
                "testPredictPlot11g[:, :] = np.nan\n",
                "testPredictPlot11g[0:Lgr, :] = x_test_predict_gru\n",
                "testPredictPlot12g = np.empty_like(dataset)\n",
                "testPredictPlot12g[:, :] = np.nan\n",
                "testPredictPlot12g[0:Lgr, :] = x_test_predict_BiGRU\n",
                "testPredictPlot13g = np.empty_like(dataset)\n",
                "testPredictPlot13g[:, :] = np.nan\n",
                "testPredictPlot13g[0:Lgr, :] = x_test_predict_gru_Att\n",
                "testPredictPlot14g = np.empty_like(dataset)\n",
                "testPredictPlot14g[:, :] = np.nan\n",
                "testPredictPlot14g[0:Lgr, :] = x_test_predict_Bigru_Att\n",
                "\n",
                "plt.figure()\n",
                "plt.plot(scaler.inverse_transform(dataset[dLgr:]), 'k', label=\"True Data\")\n",
                "plt.plot(testPredictPlot11[:], label=\"LSTM Prediction\")\n",
                "plt.plot(testPredictPlot11g[:], label=\"GRU Prediction\")\n",
                "plt.plot(testPredictPlot12[:], label=\"BiLSTM Prediction\")\n",
                "plt.plot(testPredictPlot12g[:], label=\"BiGRU Prediction\")\n",
                "plt.plot(testPredictPlot13[:], label=\"Att-LSTM Prediction\")\n",
                "plt.plot(testPredictPlot13g[:], label=\"Att-GRU Prediction\")\n",
                "plt.plot(testPredictPlot14[:], label=\"Att-BiLSTM Prediction\")\n",
                "plt.plot(testPredictPlot14g[:], label=\"Att-BiGRU Prediction\")\n",
                "\n",
                "plt.ylabel(WQPu, fontsize=12)\n",
                "plt.xlabel('Days', fontsize=12)\n",
                "plt.grid(linestyle=':', linewidth=1)\n",
                "plt.legend()\n",
                "plt.savefig('n/'+ WQPn +'_Comp_of_pred'+ l + s + e + w + b + o + d +'.pdf', dpi=300)\n",
                "plt.close()"
            ]
        }
    ],
    "metadata": {
        "extensions": {
            "azuredatastudio": {
                "version": 1,
                "views": []
            }
        },
        "interpreter": {
            "hash": "3d9542168a597b2d0444e6c29e198981e2db3768152cab7dd0ba762f50929013"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
